{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Diagnostics for More Informed Machine Learning\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "We'll do one for classification and one for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the room occupancy dataset\n",
    "occupancy = os.path.join('data','occupancy_data','datatraining.txt')\n",
    "occupancy = pd.read_csv(occupancy, sep=',')\n",
    "occupancy.columns = [\n",
    "    'date', 'temp', 'humid', 'light', 'co2', 'hratio', 'occupied'\n",
    "]\n",
    "\n",
    "# View the occupancy details\n",
    "print(occupancy.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the concrete compression data set\n",
    "concrete   = pd.read_excel(os.path.join('data','Concrete_Data.xls'))\n",
    "concrete.columns = [\n",
    "    'cement', 'slag', 'ash', 'water', 'splast',\n",
    "    'coarse', 'fine', 'age', 'strength'\n",
    "]\n",
    "\n",
    "# View the concrete details\n",
    "print(concrete.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(attributes, targets, model):\n",
    "    \"\"\"\n",
    "    Executes classification using the specified model and returns\n",
    "    a classification report.\n",
    "    \"\"\"\n",
    "    # Split data into 'test' and 'train' for cross validation\n",
    "    splits = cv.train_test_split(attributes, targets, test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true = y_test\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "def regress(attributes, targets, model):\n",
    "    # Split data into 'test' and 'train' for cross validation\n",
    "    splits = cv.train_test_split(attributes, targets, test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true = y_test\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Mean squared error = {:0.3f}\".format(mse(y_true, y_pred)))\n",
    "    print(\"R2 score = {:0.3f}\".format(r2_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model exploration tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(attributes, targets, model):\n",
    "    \"\"\"\n",
    "    Executes classification or regression using the specified model\n",
    "    and returns expected and predicted values.\n",
    "    Useful for comparison plotting.\n",
    "    \"\"\"\n",
    "    splits = cv.train_test_split(attributes, targets, test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true = y_test\n",
    "    y_pred = model.predict(X_test)\n",
    "    return (y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual model evaluation tools: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_classification_report(cr, title='Classification report', cmap=ddlheatmap):\n",
    "    lines = cr.split('\\n')\n",
    "    classes = []\n",
    "    matrix = []\n",
    "\n",
    "    for line in lines[2:(len(lines)-3)]:\n",
    "        s = line.split()\n",
    "        classes.append(s[0])\n",
    "        value = [float(x) for x in s[1: len(s) - 1]]\n",
    "        matrix.append(value)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    for column in range(len(matrix)+1):\n",
    "        for row in range(len(classes)):\n",
    "            txt = matrix[row][column]\n",
    "            ax.text(column,row,matrix[row][column],va='center',ha='center')\n",
    "\n",
    "    fig = plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(len(classes)+1)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')\n",
    "    plt.show()\n",
    "\n",
    "def roc_viz(y, yhat, model):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y,yhat)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('Receiver Operating Characteristic for %s' % model)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'blue', label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'m--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def roc_compare_two(ys, yhats, mods):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "    for y, yhat, m, ax in ((ys[0], yhats[0], mods[0], ax1), (ys[1], yhats[1], mods[1], ax2)):\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y,yhat)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        ax.set_title('ROC for %s' % m)\n",
    "        ax.plot(false_positive_rate, true_positive_rate, c=\"#2B94E9\", label='AUC = %0.2f'% roc_auc)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.plot([0,1],[0,1],'m--',c=\"#666666\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cr = classification_report(y_true, y_pred)\n",
    "plot_classification_report(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual model evaluation tools: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regr_error_viz(model,features,labels):\n",
    "    predicted = cv.cross_val_predict(model, features, labels, cv=12)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(labels, predicted)\n",
    "    ax.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "def error_compare_three(mods,X,y):\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "    for mod, ax in ((mods[0], ax1),(mods[1], ax2),(mods[2], ax3)):\n",
    "        predicted = cv.cross_val_predict(mod[0], X, y, cv=12)\n",
    "        ax.scatter(y, predicted, c=\"#F2BE2C\")\n",
    "        ax.set_title('Prediction Error for %s' % mod[1])\n",
    "        ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4, c=\"#2B94E9\")\n",
    "        ax.set_ylabel('Predicted')\n",
    "    plt.xlabel('Measured')\n",
    "    plt.show()\n",
    "\n",
    "def plot_resids(model,features,labels):\n",
    "    for feature in list(features):\n",
    "        splits = cv.train_test_split(features[[feature]], labels, test_size=0.2)\n",
    "        X_train, X_test, y_train, y_test = splits\n",
    "        model.fit(X_train, y_train)\n",
    "        plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c='#2B94E9', s=40, alpha=0.5)\n",
    "        plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c='#94BA65', s=40)\n",
    "    plt.hlines(y=0, xmin=0, xmax=100)\n",
    "    plt.title('Plotting residuals using training (blue) and test (green) data')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.xlim([20,70])\n",
    "    plt.ylim([-50,50])\n",
    "    plt.show()\n",
    "\n",
    "def resids_compare_three(mods,X,y):\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "    plt.title('Plotting residuals using training (blue) and test (green) data')\n",
    "    for mod, ax in ((mods[0], ax1),(mods[1], ax2),(mods[2], ax3)):\n",
    "        for feature in list(X):\n",
    "            splits = cv.train_test_split(X[[feature]], y, test_size=0.2)\n",
    "            X_train, X_test, y_train, y_test = splits\n",
    "            mod[0].fit(X_train, y_train)\n",
    "            ax.scatter(mod[0].predict(X_train), mod[0].predict(X_train) - y_train, c='#2B94E9', s=40, alpha=0.5)\n",
    "            ax.scatter(mod[0].predict(X_test), mod[0].predict(X_test) - y_test, c='#94BA65', s=40)\n",
    "        ax.hlines(y=0, xmin=0, xmax=100)\n",
    "        ax.set_title(mod[1])\n",
    "        ax.set_ylabel('Residuals')\n",
    "    plt.xlim([20,70])        # Adjust according to your dataset\n",
    "    plt.ylim([-50,50])       # Adjust according to your dataset\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
