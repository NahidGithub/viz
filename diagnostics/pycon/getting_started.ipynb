{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with model selection\n",
    "\n",
    "Those who have used Scikit-Learn before will no doubt already be familiar with the Choosing the Right Estimator flow chart. This diagram is handy for those who are just getting started, as it models a simplified decision-making process for selecting the machine learning algorithm that is best suited to one's dataset.\n",
    "\n",
    "![Choosing the Right Estimator](figures/scikitlearncheatsheet.png)\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import r2_score, mean_squared_error as mse\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it together. \n",
    "\n",
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the room occupancy dataset\n",
    "occupancy = os.path.join('data','occupancy_data','datatraining.txt')\n",
    "occupancy = pd.read_csv(occupancy, sep=',')\n",
    "occupancy.columns = [\n",
    "    'date', 'temp', 'humid', 'light', 'co2', 'hratio', 'occupied'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50 samples?\n",
    "\n",
    "First we are asked whether we have more than 50 samples for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(occupancy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting a quantity or a category?\n",
    "\n",
    "Next we're asked if we're predicting a category. For the occupancy dataset, the answer is yes. For occupancy, we are predicting whether a room is occupied (0 for no, 1 for yes). Therefore, we will be looking for a classifier for our occupancy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(attributes, targets, model):\n",
    "    \"\"\"\n",
    "    Executes classification using the specified model and returns\n",
    "    a classification report.\n",
    "    \"\"\"\n",
    "    # Split data into 'test' and 'train' for cross validation\n",
    "    splits = cv.train_test_split(attributes, targets, test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true = y_test\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred, target_names=list(occupancy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our categorical dataset has fewer than 100,000 instances, we are prompted to start with sklearn.svm.LinearSVC (which will map the data to a higher dimensional feature space), or failing that, sklearn.neighbors.KNeighborsClassifier (which will assign instances to the class most common among its k nearest neighbors). \n",
    "\n",
    "In our feature exploration of the occupancy dataset, you'll remember that the different attributes were not all on the same scale, so in addition to the other steps, we import scale so that we can standardize all the features before we run fit-predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = occupancy[['temp', 'humid', 'light', 'co2', 'hratio']]\n",
    "labels   = occupancy['occupied']\n",
    "\n",
    "# Scale the features\n",
    "stdfeatures = scale(features)\n",
    "\n",
    "classify(stdfeatures, labels, LinearSVC())\n",
    "classify(stdfeatures, labels, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the concrete compression data set\n",
    "concrete   = pd.read_excel(os.path.join('data','Concrete_Data.xls'))\n",
    "concrete.columns = [\n",
    "    'cement', 'slag', 'ash', 'water', 'splast',\n",
    "    'coarse', 'fine', 'age', 'strength'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50 samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(concrete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting a quantity or a category?\n",
    "\n",
    "For the concrete dataset, the labels for the strength of the concrete are continuous, so we are predicting a quantity, not a category. Therefore, we will be looking for a regressor for our concrete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regress(attributes, targets, model):\n",
    "    # Split data into 'test' and 'train' for cross validation\n",
    "    splits = cv.train_test_split(attributes, targets, test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true = y_test\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Mean squared error = {:0.3f}\".format(mse(y_true, y_pred)))\n",
    "    print(\"R2 score = {:0.3f}\".format(r2_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile for our concrete dataset, we must determine whether we think all of the features are important, or only a few of them. If we decide to keep all the features as is, the chart suggests using sklearn.linear_model.RidgeRegression (which will identify features that are less predictive and ensure they have less influence in the model) or possibly sklearn.svm.SVR with a linear kernel (which is similar to the LinearSVC classifier). If we guess that some of the features are not important, we might decide instead to choose sklearn.linear_model.Lasso (which will drop out any features that aren't predictive) or sklearn.linear_model.ElasticNet (which will try to find a happy medium between the Lasso and Ridge methods, taking the linear combination of their L1 and L2 penalties).\n",
    "\n",
    "Let's try a few because, why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = concrete[[\n",
    "    'cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age'\n",
    "]]\n",
    "labels   = concrete['strength']\n",
    "\n",
    "regress(features, labels, Ridge())\n",
    "regress(features, labels, Lasso())\n",
    "regress(features, labels, ElasticNet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the code above, the Scikit-Learn API allows us to rapidly deploy as many models as we want. This is an incredibly powerful feature of the Scikit-Learn library that cannot be understated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
